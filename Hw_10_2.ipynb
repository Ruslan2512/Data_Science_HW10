{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9700075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import *\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "conv_base = VGG16(weights=\"imagenet\", include_top=False, input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac872a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd401ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = utils.to_categorical(y_train)\n",
    "y_test =utils.to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b5b7310",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=np.reshape(x_train, (-1,28,28,1))\n",
    "x_test=np.reshape(x_test, (-1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fadfcf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([60000, 28, 28, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = Concatenate()([x_train,x_train,x_train])\n",
    "x_test = Concatenate()([x_test,x_test,x_test])\n",
    "\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "404c39cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([60000, 32, 32, 3]), TensorShape([60000, 28, 28, 3]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resized_x_train = tf.image.resize(x_train, (32,32))\n",
    "resized_x_test = tf.image.resize(x_test, (32,32))\n",
    "\n",
    "resized_x_train.shape, x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7b571c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import img_to_array\n",
    "train_X = np.asarray([img_to_array(im) for im in resized_x_train])\n",
    "test_X = np.asarray([img_to_array(im) for im in resized_x_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53774136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_val,y_train,y_val = train_test_split(train_X, y_train, test_size=0.2, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a808f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=20,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_generator = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "105a8e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator.fit(x_train)\n",
    "test_generator.fit(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ede3e684",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_generator.flow(x_train,y_train,batch_size=200)\n",
    "test_generator = test_generator.flow(x_val,y_val,batch_size=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05aa761b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10000, 28, 28, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "750596e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(150, 150, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1502a52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'block3_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc43f01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "\n",
    "original_dim = (32, 32, 3)\n",
    "target_size = (150, 150)\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Input(original_dim))\n",
    "model.add(layers.Lambda(lambda image: tf.image.resize(image, target_size)))\n",
    "model.add(conv_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(256, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22032521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lambda (Lambda)             (None, 150, 150, 3)       0         \n",
      "                                                                 \n",
      " vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 8192)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 256)               2097408   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,846,282\n",
      "Trainable params: 16,586,122\n",
      "Non-trainable params: 260,160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5425666d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 35/100 [=========>....................] - ETA: 27:44 - loss: 1.7755 - acc: 0.3730"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "checkpointer = ModelCheckpoint(filepath='best_weights.hdf5',verbose=1, save_best_only= True)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.RMSprop(1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    epochs=3,\n",
    "                    steps_per_epoch=100,\n",
    "                    validation_data=test_generator,\n",
    "                    validation_steps=60,\n",
    "                    shuffle=True,\n",
    "                    callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9d4483",
   "metadata": {},
   "source": [
    "Epoch 1/3\n",
    "100/100 [==============================] - ETA: 0s - loss: 1.1937 - acc: 0.5699 \n",
    "Epoch 1: val_loss improved from inf to 0.60829, saving model to best_weights.hdf5\n",
    "100/100 [==============================] - 3043s 30s/step - loss: 1.1937 - acc: 0.5699 - val_loss: 0.6083 - val_acc: 0.7742\n",
    "Epoch 2/3\n",
    "100/100 [==============================] - ETA: 0s - loss: 0.6370 - acc: 0.7627 \n",
    "Epoch 2: val_loss improved from 0.60829 to 0.40162, saving model to best_weights.hdf5\n",
    "100/100 [==============================] - 2047s 20s/step - loss: 0.6370 - acc: 0.7627 - val_loss: 0.4016 - val_acc: 0.8511\n",
    "Epoch 3/3\n",
    "100/100 [==============================] - ETA: 0s - loss: 0.5259 - acc: 0.8074 \n",
    "Epoch 3: val_loss did not improve from 0.40162\n",
    "100/100 [==============================] - 1775s 18s/step - loss: 0.5259 - acc: 0.8074 - val_loss: 0.4323 - val_acc: 0.8152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f49311c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['acc'],label='acc')\n",
    "plt.plot(history.history['val_acc'],label='val_acc')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c251c622",
   "metadata": {},
   "source": [
    "<matplotlib.legend.Legend at 0x1ae942fb9d0>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265732d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'],label='loss')\n",
    "plt.plot(history.history['val_loss'],label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc865404",
   "metadata": {},
   "source": [
    "<matplotlib.legend.Legend at 0x1ae94407a60>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793d859a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tf.image.resize(x_test,(150,150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f216ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "test_generator = test_generator.flow(\n",
    "        x_test,\n",
    "        y_test,\n",
    "        batch_size=200)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=50)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d1b4f2",
   "metadata": {},
   "source": [
    "50/50 [==============================] - 245s 5s/step - loss: 0.4603 - acc: 0.8066\n",
    "test acc: 0.8065999746322632"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc8d52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('best_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9599af9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")\n",
    "\n",
    "test_generator.fit(x_test)\n",
    "\n",
    "test_generator = test_generator.flow(\n",
    "        x_test,\n",
    "        y_test,\n",
    "        batch_size=200)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=50)\n",
    "print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6832f44",
   "metadata": {},
   "source": [
    "50/50 [==============================] - 245s 5s/step - loss: 0.4249 - acc: 0.8434\n",
    "test acc: 0.8434000015258789"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
